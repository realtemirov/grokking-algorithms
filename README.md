---
cover: >-
  https://images.unsplash.com/photo-1542903660-eedba2cda473?crop=entropy&cs=srgb&fm=jpg&ixid=M3wxOTcwMjR8MHwxfHNlYXJjaHwxMHx8cHJvZ3JhbW1pbmd8ZW58MHx8fHwxNjg5NTAxMDY2fDA&ixlib=rb-4.0.3&q=85
coverY: -65
---

# Content

## 1. Introduction to Algorithms

* [Introduction](<1. Introduction to Algorithms/1. Introduction.md>)
  * [What you'll learn about performance](<1. Introduction to Algorithms/1. Introduction.md#what-youll-learn-about-performance>)
  * [What you'll learn about solving problems](1.%20Introduction%20to%20Algorithms/01%20Introduction.md#what-youll-learn-about-solving-problems)
* [Binary search](<1. Introduction to Algorithms/2. Binary Search.md>)
  * [A better way to search](<1. Introduction to Algorithms/2. Binary Search.md#a-better-way-to-search>)
  * [Running time](<1. Introduction to Algorithms/2. Binary Search.md#running-time>)
* [Big O notation](<1. Introduction to Algorithms/3. Big O notation.md>)
  * [Algorithm running times grow at different rates](<1. Introduction to Algorithms/3. Big O notation.md#algorithm-running-times-grow-at-different-rates>)
  * [Visualizing different Big O run times](<1. Introduction to Algorithms/3. Big O notation.md#visualizing-different-big-o-run-times>)
  * [Big O establishes a worst-case run time](<1. Introduction to Algorithms/3. Big O notation.md#big-o-establishes-a-worst-case-run-time>)
  * [Some common Big O run times](<1. Introduction to Algorithms/3. Big O notation.md#some-common-big-o-run-times>)
  * [The traveling salesperson](<1. Introduction to Algorithms/3. Big O notation.md#the-traveling-salesperson>)
* [Recap](<1. Introduction to Algorithms/4. Recap.md>)

## 2. Selection sort

* [How memory works](<2. Selection sort/1. How memory works.md>)
* [Arrays and linked lists](<2. Selection sort/2. Arrays and linked lists.md>)
  * [Linked lists](<2. Selection sort/2. Arrays and linked lists.md#linked-lists>)
  * [Arrays](<2. Selection sort/2. Arrays and linked lists.md#arrays>)
  * [Terminology](<2. Selection sort/2. Arrays and linked lists.md#terminology>)
  * [Inserting into the middle of a list](<2. Selection sort/2. Arrays and linked lists.md#inserting-into-the-middle-of-a-list>)
  * [Deletions](<2. Selection sort/2. Arrays and linked lists.md#deletions>)
* [Selection sort](<2. Selection sort/3. Selection sort.md>)
* [Recap](<2. Selection sort/4. Recap.md>)

## 3. Recursion

* [Recursion](<3. Recursion/1. Recursion.md>)
* [Base case and recursive case](<3. Recursion/2. Base case and recursive case.md>)
* [The stack](<3. Recursion/3. The stack.md>)
  * [The call stack](<3. Recursion/3. The stack.md#the-call-stack>)
  * [The call stack with recursion](<3. Recursion/3. The stack.md#the-call-stack-with-recursion>)
* [Recap](<3. Recursion/4. Recap.md>)

## 4. Quicksort

* [Divide & conquer](<4. Quicksort/1. Divide & conquer.md>)
* [Quicksort](<4. Quicksort/2. Quicksort.md>)
* [Big O notation revisited](<4. Quicksort/3. Big O notation revisited.md>)
  * [Merge sort vs. quicksort](<4. Quicksort/3. Big O notation revisited.md#merge-sort-vs.-quicksort>)
  * [Average case vs. worst case](<4. Quicksort/3. Big O notation revisited.md#average-case-vs.-worst-case>)
* [Recap](<4. Quicksort/4. Recap.md>)

## 5. Hash tables

* [Hash functions](<5. Hash tables/1. Hash functions.md>)
* [Use cases](<5. Hash tables/2. Use cases.md>)
  * [Using hash tables for lookups](<5. Hash tables/2. Use cases.md/#using-hash-tables-for-lookups>)
  * [Preventing duplicate entries](<5. Hash tables/2. Use cases.md/#preventing-duplicate-entries>)
  * [Using hash tables as a cache](<5. Hash tables/2. Use cases.md/#using-hash-tables-as-a-cache>)
  * [Recap](<5. Hash tables/2. Use cases.md/#recap>)
* [Collisions](<5. Hash tables/3. Collisions.md>)
* [Performance](<5. Hash tables/4. Performance.md>)
  * [Load factor](<5. Hash tables/4. Performance.md#load-factor>)
  * [A good hash function](<5. Hash tables/4. Performance.md#a-good-hash-function>)
* [Recap](<5. Hash tables/5. Recap.md>)

## 6. Breadth-first search

* [Introduction to graph](<6. Breadth-first search/1. Introduction to graph.md>)
* [What is a graph](<6. Breadth-first search/2. What is a graph.md>)
* [Breadth-first search](<6. Breadth-first search/3. Breadth-first search.md>)
  * [Finding the shortes path](<6. Breadth-first search/3. Breadth-first search.md#finding-the-shortes-path>)
  * [Queues](<6. Breadth-first search/3. Breadth-first search.md#queues>)
* [Implementing the graph](<6. Breadth-first search/4. Implementing the graph.md>)
* [Implementing the algorithm](<6. Breadth-first search/5. Implementing the algorithm.md>)
  * [Running time](<6. Breadth-first search/5. Implementing the algorithm.md#running-time>)
* [Recap](<6. Breadth-first search/6. Recap.md>)

## 7. Dijkstra's algorithm

* [Working with Dijkstra's algorithm](<7. Dijkstra's algorithm/1. Working with Dijkstra's algorithm.md>)
* [Terminology](<7. Dijkstra's algorithm/2. Terminology.md>)
* [Trading for a piano](<7. Dijkstra's algorithm/3. Trading for a piano.md>)
* [Negative-weight edges](<7. Dijkstra's algorithm/4. Negative-weight edges.md>)
* [Implementation](<7. Dijkstra's algorithm/5. Implementation.md>)
* [Recap](<7. Dijkstra's algorithm/6. Recap.md>)

## 8. Greedy Algorithms

* [The classroom scheduling problem](<8. Greedy Algorithms/1. The classroom scheduling problem.md>)
* [The knapsack problem](<8. Greedy Algorithms/2. The knapsack problem.md>)
* [The set-covering problem](<8. Greedy Algorithms/3. The set-covering problem.md>)
  * [Approximation algorithms](<8. Greedy Algorithms/3. The set-covering problem.md#approximation-algorithms>)
* [NP-complete problems](<8. Greedy Algorithms/4. NP-complete problems.md>)
* [Traveling salesperson, step by step](<8. Greedy Algorithms/5. Traveling salesperson, step by step.md>)
  * [How do you tell if a problem is NP-complete?](<8. Greedy Algorithms/5. Traveling salesperson, step by step.md#how-do-you-tell-if-a-problem-is-np-complete>)
* [Recap](<8. Greedy Algorithms/6. Recap.md>)

## 9. Dynamic programming

* [The knapsack problem](<9. Dynamic programming/1. The knapsack problem.md>)
  * [The simple solution](<9. Dynamic programming/1. The knapsack problem.md#the-simple-solution>)
  * [Dynamic programming](<9. Dynamic programming/1. The knapsack problem.md#dynamic-programming>)
* [Knapsack problem FAQ](<9. Dynamic programming/2. Knapsack problem FAQ.md>)
  * [What happens if you add an item?](<9. Dynamic programming/2. Knapsack problem FAQ.md#what-happens-if-you-add-an-item>)
  * [What happens if you change the order of the rows?](<9. Dynamic programming/2. Knapsack problem FAQ.md#what-happens-if-you-change-the-order-of-the-rows>)
  * [Can you fill in the grid column-wise instead of row-wise?](<9. Dynamic programming/2. Knapsack problem FAQ.md#can-you-fill-in-the-grid-column-wise-instead-of-row-wise>)
  * [What happens if you add a smaller item?](<9. Dynamic programming/2. Knapsack problem FAQ.md#what-happens-if-you-add-a-smaller-item>)
  * [Can you steal fractions of an item?](<9. Dynamic programming/2. Knapsack problem FAQ.md#can-you-steal-fractions-of-an-item>)
  * [Optimizing your travel itinerary](<9. Dynamic programming/2. Knapsack problem FAQ.md#optimizing-your-travel-itinerary>)
  * [Handling items that depend on each other](<9. Dynamic programming/2. Knapsack problem FAQ.md#handling-items-that-depend-on-each-other>)
  * [Is it possible that the solution will require more than two sub-knapsacks?](<9. Dynamic programming/2. Knapsack problem FAQ.md#is-it-possible-that-the-solution-will-require-more-than-two-sub-knapsacks>)
  * [Is it possible that the best solution doesn't fill the knapsack completely?](<9. Dynamic programming/2. Knapsack problem FAQ.md#is-it-possible-that-the-best-solution-doesnt-fill-the-knapsack-completely>)
* [Longest common substring](<9. Dynamic programming/3. Longest common substring.md>)
  * [Making the grid](<9. Dynamic programming/3. Longest common substring.md#making-the-grid>)
  * [Filling in the grid](<9. Dynamic programming/3. Longest common substring.md#filling-in-the-grid>)
  * [The solution](<9. Dynamic programming/3. Longest common substring.md#the-solution>)
  * [Longest common subsequence](<9. Dynamic programming/3. Longest common substring.md#longest-common-subsequence>)
  * [Longest common subsequenceâ€”solution](<9. Dynamic programming/3. Longest common substring.md#longest-common-subsequencesolution>)
* [Recap](<9. Dynamic programming/4. Recap.md>)

## 10. K-nearest neighbors

* [Classifying oranges vs. grapefruit](<10. K-nearest neighbors/1. Classifying oranges vs. grapefruit.md>)
* [Building a recommendations system](<10. K-nearest neighbors/2. Building a recommendations system.md>)
  * [Feature extraction](<10. K-nearest neighbors/2. Building a recommendations system.md#feature-extraction>)
  * [Regression](<10. K-nearest neighbors/2. Building a recommendations system.md#regression>)
  * [Picking good features](<10. K-nearest neighbors/2. Building a recommendations system.md#picking-good-features>)
* [Introduction to machine learning](<10. K-nearest neighbors/3. Introduction to machine learning.md>)
  * [OCR](<10. K-nearest neighbors/3. Introduction to machine learning.md#ocr>)
  * [Building a spam filter](<10. K-nearest neighbors/3. Introduction to machine learning.md#building-a-spam-filter>)
  * [Predicting the stock market](<10. K-nearest neighbors/3. Introduction to machine learning.md#predicting-the-stock-market>)
* [Recap](<10. K-nearest neighbors/4. Recap.md>)

## 11. Where to go next
* [Trees](<11. Where to go next/1. Trees.md>)
* [Inverted indexes](<11. Where to go next/2. Inverted indexes.md>)
* [The Fourier transform](<11. Where to go next/3. The Fourier transform.md>)
* [Parallel algorithms](<11. Where to go next/4. Parallel algorithms.md>)
* [MapReduce](<11. Where to go next/5. MapReduce.md>)
  * [Why are distributed algorithms useful?](<11. Where to go next/5. MapReduce.md#why-are-distributed-algorithms-useful>)
  * [The map function](<11. Where to go next/5. MapReduce.md#the-map-function>)
  * [The reduce function](<11. Where to go next/5. MapReduce.md#the-reduce-function>)
* [Bloom filters and HyperLogLog](<11. Where to go next/6. Bloom filters and HyperLogLog.md>)
  * [Bloom filters](<11. Where to go next/6. Bloom filters and HyperLogLog.md#bloom-filters>)
  * [HyperLogLog](<11. Where to go next/6. Bloom filters and HyperLogLog.md#hyperloglog>)
* [The SHA algorithms](<11. Where to go next/7. The SHA algorithms.md>)
  * [Comparing files](<11. Where to go next/7. The SHA algorithms.md#comparing-files>)
  * [Checking passwords](<11. Where to go next/7. The SHA algorithms.md#checking-passwords>)
* [Locality-sensitive hashing](<11. Where to go next/8. Locality-sensitive hashing.md>)
* [Diffie-Hellman key exchange](<11. Where to go next/9. Diffie-Hellman key exchange.md>)
* [Linear programming](<11. Where to go next/10. Linear programming.md>)
* [Epilogue](<11. Where to go next/11. Epilogue.md>)

## Answers to exercises

* [Chapter 1](<12. Answers to exercises/Chapter 1.md>)
* [Chapter 2](<12. Answers to exercises/Chapter 2.md>)
* [Chapter 3](<12. Answers to exercises/Chapter 3.md>)
* [Chapter 4](<12. Answers to exercises/Chapter 4.md>)
* [Chapter 5](<12. Answers to exercises/Chapter 5.md>)
* [Chapter 6](<12. Answers to exercises/Chapter 6.md>)
* [Chapter 7](<12. Answers to exercises/Chapter 7.md>)
* [Chapter 8](<12. Answers to exercises/Chapter 8.md>)
* [Chapter 9](<12. Answers to exercises/Chapter 9.md>)
* [Chapter 10](<12. Answers to exercises/Chapter 10.md>)